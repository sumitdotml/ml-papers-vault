>[!NOTE]
>**My question re paper reading**: "Do you guys think reading 1,000 papers a year is viable as an ml researcher? I've just been told that people who're at the very top tend to reach almost 2,000 papers a year and I've been left speechless"

1. to answer my question, one could say 1000 is "not feasible" but it's not even about feasibility; numbers don't mean everything. So, in a way, paper count is a 'silly proxy' and quality over quantity is always preferred (although the skill to define what 'quality' is comes with experience, apparently).

2. some papers require us to go deep into each one of their concepts (e.g., seminal papers like the Transformer), but a lot don't & can be covered through getting the main takeaways and learnings.

3. "When you keep reading papers (of the same domain), you start to see patterns emerge, and also you don't read end to end, skim over it, read important parts" - Vishal

So, my main takeaways:
- just keep reading & don't worry too much about the count
- more reading means getting better at understanding quickly what the main ideas are, filtering out noise, and importantly, effectively skimming papers
- document the learnings well, take notes, make a mental model
- not every paper needs to be read thoroughly (unless there are reasons)